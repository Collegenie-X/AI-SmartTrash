import streamlit as st
import tensorflow as tf
import numpy as np
from pathlib import Path
import tempfile
import cv2
from PIL import Image
import io
import pandas as pd

from app.config.constants import (
    ALLOWED_EXTENSIONS,
    MAX_FILE_SIZE_MB,
    IMAGE_SIZE,
    IMAGE_CHANNELS,
    CATEGORIES,
    CONFIDENCE_LEVELS,
    RECYCLING_GUIDES,
    APP_TITLE,
    APP_DESCRIPTION,
    CAMERA_CONFIG,
    SECOND_PREDICTION_THRESHOLD
)
from app.config.settings import MODEL_PATH, LABELS_PATH, logger


class ModelManager:
    def __init__(self):
        self.model = None
        self.labels = []
        self.interpreter = None

    def load_model(self, model_file):
        try:
            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            with tempfile.NamedTemporaryFile(delete=False, suffix=".tflite") as tmp_file:
                tmp_file.write(model_file.getvalue())
                tmp_file_path = tmp_file.name

            # TFLite ì¸í„°í”„ë¦¬í„° ì´ˆê¸°í™”
            self.interpreter = tf.lite.Interpreter(model_path=tmp_file_path)
            self.interpreter.allocate_tensors()

            # ëª¨ë¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            self.input_details = self.interpreter.get_input_details()
            self.output_details = self.interpreter.get_output_details()

            st.success("ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
            logger.info("ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
            return True
        except Exception as e:
            st.error(f"ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            logger.error(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return False

    def load_labels(self, labels_file):
        try:
            content = labels_file.getvalue().decode("utf-8")
            self.labels = [label.strip() for label in content.split("\n") if label.strip()]
            st.success("ë¼ë²¨ íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
            logger.info("ë¼ë²¨ íŒŒì¼ ë¡œë“œ ì„±ê³µ")
            return True
        except Exception as e:
            st.error(f"ë¼ë²¨ íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            logger.error(f"ë¼ë²¨ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return False

    def preprocess_image(self, image):
        # ì´ë¯¸ì§€ë¥¼ ëª¨ë¸ ì…ë ¥ í¬ê¸°ë¡œ ì¡°ì •
        image = tf.image.resize(image, IMAGE_SIZE)
        # ì •ê·œí™”
        image = image / 255.0
        return image

    def predict(self, input_data):
        if self.interpreter is None or not self.labels:
            st.error("ëª¨ë¸ê³¼ ë¼ë²¨ì„ ë¨¼ì € ë¡œë“œí•´ì£¼ì„¸ìš”.")
            return None

        try:
            input_data = np.array(input_data, dtype=np.float32)
            input_data = np.expand_dims(input_data, axis=0)

            self.interpreter.set_tensor(self.input_details[0]["index"], input_data)
            self.interpreter.invoke()
            output_data = self.interpreter.get_tensor(self.output_details[0]["index"])

            predictions = output_data[0]
            sorted_indices = np.argsort(predictions)[::-1]
            
            # Get English label and its Korean translation
            def get_label_info(label):
                # Convert label to uppercase and replace spaces with underscores
                category_key = label.upper().replace(" ", "_")
                return {
                    "english_label": category_key,
                    "confidence": float(predictions[sorted_indices[0]]),
                    "korean_label": CATEGORIES.get(category_key, "ì•Œ ìˆ˜ ì—†ìŒ")
                }
            
            # ìµœìƒìœ„ ì˜ˆì¸¡
            top_prediction = get_label_info(self.labels[sorted_indices[0]])

            # ë‘ ë²ˆì§¸ ì˜ˆì¸¡ (ì‹ ë¢°ë„ ì°¨ì´ê°€ SECOND_PREDICTION_THRESHOLD ì´ë‚´ì¸ ê²½ìš°)
            second_prediction = None
            if len(sorted_indices) > 1:
                confidence_diff = predictions[sorted_indices[0]] - predictions[sorted_indices[1]]
                if confidence_diff < SECOND_PREDICTION_THRESHOLD:
                    second_prediction = get_label_info(self.labels[sorted_indices[1]])

            return {
                "top_prediction": top_prediction,
                "second_prediction": second_prediction,
                "all_predictions": [
                    get_label_info(self.labels[idx])
                    for idx in sorted_indices
                ]
            }
        except Exception as e:
            st.error(f"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            logger.error(f"ì˜ˆì¸¡ ì‹¤íŒ¨: {str(e)}")
            return None


def process_image_file(image_file, model_manager):
    try:
        # íŒŒì¼ í¬ê¸° ê²€ì‚¬
        if len(image_file.getvalue()) > MAX_FILE_SIZE_MB * 1024 * 1024:
            st.error(f"íŒŒì¼ í¬ê¸°ê°€ {MAX_FILE_SIZE_MB}MBë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤.")
            return None

        # íŒŒì¼ í™•ì¥ì ê²€ì‚¬
        file_ext = image_file.name.split(".")[-1].lower()
        if file_ext not in ALLOWED_EXTENSIONS:
            st.error(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. ì§€ì› í˜•ì‹: {', '.join(ALLOWED_EXTENSIONS)}")
            return None

        image = Image.open(image_file)
        image_array = np.array(image)
        processed_image = model_manager.preprocess_image(image_array)
        return processed_image
    except Exception as e:
        st.error(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        logger.error(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
        return None


def process_camera_frame(frame, model_manager):
    try:
        # BGRì„ RGBë¡œ ë³€í™˜
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        processed_frame = model_manager.preprocess_image(frame_rgb)
        return processed_frame
    except Exception as e:
        st.error(f"ì¹´ë©”ë¼ í”„ë ˆì„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        logger.error(f"ì¹´ë©”ë¼ í”„ë ˆì„ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
        return None


def display_prediction_results(result):
    if result and result["top_prediction"]:
        st.write("### ğŸ¯ ë¶„ë¥˜ ê²°ê³¼")

        # ì£¼ìš” ì˜ˆì¸¡ ê²°ê³¼
        top_pred = result["top_prediction"]
        confidence = top_pred["confidence"]
        
        # ì‹ ë¢°ë„ì— ë”°ë¥¸ ìƒ‰ìƒ ì„¤ì •
        if confidence >= CONFIDENCE_LEVELS["HIGH"]:
            confidence_color = "green"
        elif confidence >= CONFIDENCE_LEVELS["MEDIUM"]:
            confidence_color = "yellow"
        else:
            confidence_color = "red"

        col1, col2 = st.columns(2)
        with col1:
            st.metric("ë¶„ë¥˜", f"{top_pred['korean_label']} ({top_pred['english_label']})")
        with col2:
            st.metric("ì‹ ë¢°ë„", f"{confidence*100:.1f}%")

        # ì§„í–‰ë¥  ë°”ë¡œ ì‹ ë¢°ë„ í‘œì‹œ
        st.markdown(f'<div style="color: {confidence_color}">ì‹ ë¢°ë„: {confidence*100:.1f}%</div>', unsafe_allow_html=True)
        st.progress(float(confidence))

        # ë¶„ë¦¬ìˆ˜ê±° ê°€ì´ë“œ í‘œì‹œ
        if top_pred["english_label"] in RECYCLING_GUIDES:
            st.write("### ğŸ“ ë¶„ë¦¬ìˆ˜ê±° ê°€ì´ë“œ")
            for guide in RECYCLING_GUIDES[top_pred["english_label"]]:
                st.write(f"- {guide}")

        # ë‘ ë²ˆì§¸ ì˜ˆì¸¡ ê²°ê³¼ í‘œì‹œ (ìˆëŠ” ê²½ìš°)
        if result["second_prediction"]:
            second_pred = result["second_prediction"]
            st.write("### ğŸ¤” ë‹¤ë¥¸ ê°€ëŠ¥ì„±")
            st.write(f"{second_pred['korean_label']} ({second_pred['english_label']}) (ì‹ ë¢°ë„: {second_pred['confidence']*100:.1f}%)")

        # ëª¨ë“  í´ë˜ìŠ¤ì— ëŒ€í•œ ì˜ˆì¸¡ í™•ë¥ ì„ ì°¨íŠ¸ë¡œ í‘œì‹œ
        st.write("### ğŸ“Š ì „ì²´ ì˜ˆì¸¡ í™•ë¥ ")
        predictions_df = pd.DataFrame(
            [(f"{pred['korean_label']} ({pred['english_label']})", pred["confidence"]) 
             for pred in result["all_predictions"]],
            columns=["í´ë˜ìŠ¤", "í™•ë¥ "]
        )
        st.bar_chart(predictions_df.set_index("í´ë˜ìŠ¤"))


def main():
    st.title(APP_TITLE)
    st.write(APP_DESCRIPTION)

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "model_manager" not in st.session_state:
        st.session_state.model_manager = ModelManager()

    # ì‚¬ì´ë“œë°”ì— íŒŒì¼ ì—…ë¡œë“œ ìœ„ì ¯ ë°°ì¹˜
    with st.sidebar:
        st.header("ëª¨ë¸ & ë¼ë²¨ ì—…ë¡œë“œ")

        model_file = st.file_uploader(
            "TFLite ëª¨ë¸ íŒŒì¼ ì„ íƒ (.tflite)",
            type=["tflite"],
            help="í•™ìŠµëœ TFLite ëª¨ë¸ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.",
        )

        labels_file = st.file_uploader(
            "ë¼ë²¨ íŒŒì¼ ì„ íƒ (.txt)",
            type=["txt"],
            help="í´ë˜ìŠ¤ ë¼ë²¨ì´ í¬í•¨ëœ í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.",
        )

        if model_file and labels_file:
            if st.button("ëª¨ë¸ & ë¼ë²¨ ë¡œë“œ"):
                model_loaded = st.session_state.model_manager.load_model(model_file)
                labels_loaded = st.session_state.model_manager.load_labels(labels_file)

                if model_loaded and labels_loaded:
                    st.success(
                        "ëª¨ë¸ê³¼ ë¼ë²¨ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤! ì´ì œ ë¶„ë¥˜ë¥¼ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                    )

    # ë©”ì¸ ì˜ì—­
    if (
        st.session_state.model_manager.interpreter is not None
        and st.session_state.model_manager.labels
    ):
        # íƒ­ ìƒì„±
        tab1, tab2 = st.tabs(["ğŸ“¸ ì´ë¯¸ì§€ ì—…ë¡œë“œ", "ğŸ“¹ ì¹´ë©”ë¼ ì°ê¸°"])

        # ì´ë¯¸ì§€ ì—…ë¡œë“œ íƒ­
        with tab1:
            st.header("ì´ë¯¸ì§€ íŒŒì¼ë¡œ ë¶„ë¥˜í•˜ê¸°")
            image_file = st.file_uploader(
                "ë¶„ë¥˜í•  ì´ë¯¸ì§€ ì„ íƒ", type=["jpg", "jpeg", "png"]
            )

            if image_file:
                st.image(image_file, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_column_width=True)

                if st.button("ì´ë¯¸ì§€ ë¶„ë¥˜ ì‹œì‘"):
                    processed_image = process_image_file(
                        image_file, st.session_state.model_manager
                    )
                    result = st.session_state.model_manager.predict(processed_image)
                    display_prediction_results(result)

        # ì‹¤ì‹œê°„ ì¹´ë©”ë¼ íƒ­
        with tab2:
            st.header("ì¹´ë©”ë¼ë¡œ ì°ê¸°")
            camera_placeholder = st.empty()

            if st.button("ì¹´ë©”ë¼ ì‹œì‘/ì •ì§€", key="camera_toggle"):
                cap = cv2.VideoCapture(0)

                try:
                    while True:
                        ret, frame = cap.read()
                        if not ret:
                            st.error("ì¹´ë©”ë¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                            break

                        # í”„ë ˆì„ ì²˜ë¦¬ ë° ì˜ˆì¸¡
                        processed_frame = process_camera_frame(
                            frame, st.session_state.model_manager
                        )
                        result = st.session_state.model_manager.predict(processed_frame)

                        # í”„ë ˆì„ì— ê²°ê³¼ í‘œì‹œ
                        if result:
                            label = result["top_prediction"]["korean_label"]
                            confidence = result["top_prediction"]["confidence"]
                            cv2.putText(
                                frame,
                                f"{label} ({confidence*100:.1f}%)",
                                (10, 30),
                                cv2.FONT_HERSHEY_SIMPLEX,
                                1,
                                (0, 255, 0),
                                2,
                            )

                        # í”„ë ˆì„ í‘œì‹œ
                        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                        camera_placeholder.image(frame_rgb, channels="RGB")

                        # ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì§€ í™•ì¸
                        if not st.session_state.get("run_camera", True):
                            break

                finally:
                    cap.release()
                    st.session_state.run_camera = False
    else:
        st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ ëª¨ë¸ê³¼ ë¼ë²¨ íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")


if __name__ == "__main__":
    main()
